{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas            as pd\n",
    "import math\n",
    "import keras\n",
    "from scipy.stats  import norm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras        import backend as K\n",
    "from datetime     import datetime\n",
    "from keras.optimizers      import RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.pylab      import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "# number of inputs to be fed\n",
    "look_back    = 288\n",
    "# number of outputs to be generated\n",
    "look_forward = 24\n",
    "# the number of stations\n",
    "stations     = 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepares the Dataset For the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The interval between each dataset (original data in 5 minute intervals)\n",
    "time_grouping = '5min'\n",
    "# load the dataset\n",
    "dataframe = pd.read_csv('ignored_assets/paxout_table.csv', engine='python', nrows=288*21)\n",
    "dataframe['time_bucket'] = pd.to_datetime(dataframe['time_bucket'])\n",
    "dataframe = dataframe.set_index('time_bucket')\n",
    "# dataframe['total'] = dataframe.sum(axis=1)\n",
    "dataframe['day_hour'] = dataframe.index.round(time_grouping)\n",
    "dataframe = dataframe.groupby('day_hour').sum()\n",
    "# removes the timestamp at column 67\n",
    "dataset_orig = dataframe.values[:,:stations]\n",
    "dataset_orig = dataset_orig.astype('float32')\n",
    "# scale the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset_orig)\n",
    "\n",
    "# convert an array of values into a dataset matrix, adjusted to make a dateset that is 66 wide\n",
    "def create_dataset(dataset, look_back=1, look_forward=2):\n",
    "    dataX, dataY = [], []\n",
    "    np.array(dataY)\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back),:]\n",
    "        # Makes sure that the array isn't the last 2 or 3 or whatever bits. It has to be the full 24\n",
    "        if len(dataset[i + look_back:i+look_back+look_forward, 0]) == look_forward:\n",
    "            dataX.append(a.T)\n",
    "            dataY.append(dataset[i + look_back:i+look_back+look_forward, :].T)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = 288*14\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset)-look_forward,:]\n",
    "\n",
    "# reshape into X=[t, t-1, t-2,..., t-look_back] and Y=[t+1, t+2,... t+look_forward]\n",
    "trainX, trainY = create_dataset(train, look_back, look_forward)\n",
    "trainX, trainY = create_dataset(test, look_back, look_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_heavy_loss (y_true, y_pred):\n",
    "    w = np.arange(1,0, -1./24) ** 2\n",
    "    w = (w / w.sum())[:,None]\n",
    "    W = K.variable(value = w)\n",
    "    return K.dot( K.abs(y_pred-y_true), W)\n",
    "\n",
    "def top_heavy_tail_heavy (y_true, y_pred):\n",
    "    # This is the normal weights that decrease\n",
    "    # w = np.arange(1, 0, -1./24)**1.3\n",
    "    # This is the Weights with one difference, The last is weighted as equally as the first\n",
    "    w = np.append(np.arange(1,1./23, -1./24)**2.5, [1])\n",
    "    w = w / w.sum()\n",
    "    w = w[:,None]\n",
    "    W = K.variable(value = w)\n",
    "    return K.dot( K.abs(y_pred-y_true), W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Custom Grid Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  My Custom Grid Search Function:\n",
    "    * trainX       - The input data for the model\n",
    "    * trainY       - The target data for the model\n",
    "    * create_model - The function which returns a compiled model\n",
    "    * param_grid   - The parameters for the function to grid search through\n",
    "    * batch_size   - The default batch size if not otherwise specified directly or as a parameter to grid search\n",
    "    * epochs       - The default number of epochs if not otherwise specified directly or as a parameter to grid search through\n",
    "    * verbose      - The verbose level when training the individual prameters\n",
    "    * seed         - The seed to be applied to each model \n",
    "'''\n",
    "def custom_grid_search(trainX, trainY, create_model, param_grid, batch_size=25, epochs=10, verbose=3, seed=None):\n",
    "    # creates an array of the keys\n",
    "    keys = np.array(param_grid.keys())\n",
    "    # feeds the keys, the full dictionary, and a fresh dictionary to the recursive function\n",
    "    # to get an array of dictionaries of every possible combination of parameters\n",
    "    indiv_params = combine_parameters (keys, param_grid, dict())\n",
    "    # An array which will keep track of the accuracy of each iteration of the parameters\n",
    "    results = np.zeros(indiv_params.size)\n",
    "    # Runs each of the possible combinations\n",
    "    for i in range(indiv_params.size):\n",
    "        # prevents changing the original set of parameters\n",
    "        indiv_param = indiv_params[i].copy()\n",
    "        # Saves batch_size and epochs for the fitting of the model, not the creation/compilation of\n",
    "        if 'batch_size' in keys:\n",
    "            batch_size = indiv_param.pop('batch_size', None)\n",
    "        if 'epochs' in keys:\n",
    "            epochs = indiv_param.pop('epochs', None)\n",
    "        # if a seed has been specified, use it\n",
    "        if seed != None:\n",
    "            np.random.seed(seed)\n",
    "        # Creates the model and trains it\n",
    "        model = create_model(**indiv_param)\n",
    "        model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        # Stores this iteration's results\n",
    "        results[i] = np.mean(model.evaluate(trainX, trainY, verbose=3))\n",
    "        # Clears the backend session in an attempt to save memory with each model\n",
    "        K.clear_session()\n",
    "    # finds the index of the result with the lowest loss value\n",
    "    best_i = np.argwhere(results == min(results) )\n",
    "    \n",
    "    best_results = results[best_i].reshape(1)[0]\n",
    "    best_params  = indiv_params[best_i].reshape(1)[0]\n",
    "    # Returns all the results and their respective parameters in order\n",
    "    return dict(results=results,\n",
    "                parameters=indiv_params,\n",
    "                best_results = best_results,\n",
    "                best_parameters = best_params)\n",
    "\n",
    "'''\n",
    "  Given a Dictionary, the keys yet to be looped through, and a specific instance of the dictionary \n",
    "  it returns an array of dictionaries showing all unique combinations of the values\n",
    "  \n",
    "  e.g. given a dictionary (a=[0, 1], b=[0, 1]), it will return the following array\n",
    "  array([\n",
    "    dict(a=0, b=0),\n",
    "    dict(a=0, b=1),\n",
    "    dict(a=1, b=0),\n",
    "    dict(a=1, b-1)\n",
    "  ])\n",
    "  \n",
    "  The Structure is as follows:\n",
    "\n",
    "    The function is given an array of keys ['a', 'b'] and a dictionary (a=[0,1], b=[0, 1])\n",
    "\n",
    "    It loops through the first key, in this case a âˆˆ {0, 1} and removes the first key from the array,\n",
    "    its new value being ['b']\n",
    "\n",
    "    It then loops through all the values of the first key, creating a variable called specific_dict, \n",
    "    which is a dictionary with the given value of a (as well as any previously defined keys in specific_dict)\n",
    "      (a=0), and (a=1)\n",
    "\n",
    "    It then calls itself, providing the updated list of keys yet to be iterated through, the full dictionary,\n",
    "    and the specific_dict each for loop\n",
    "\n",
    "    Once the list of keys yet to be iterated through is of size 1, it ceases the recursion\n",
    "  \n",
    "'''\n",
    "def combine_parameters(keys, full_dict, specific_dict):\n",
    "    result = np.array([])\n",
    "    # If the size of the keys array is 1, that means this is the final key to be looped through, cease recursion\n",
    "    if keys.size == 1:\n",
    "        for i in range(len(full_dict[keys[0]])):\n",
    "            specific_dict = specific_dict.copy()\n",
    "            # the result will be the specific dict followed by every value in this \n",
    "            specific_dict[keys[0]] = full_dict[keys[0]][i]\n",
    "            result = np.append(result, specific_dict)\n",
    "        return result\n",
    "    else:\n",
    "        # keeps the first key\n",
    "        current_key = keys[0]\n",
    "        # removes the first key from the list of keys that havent been looped through yet\n",
    "        keys = keys[1:]\n",
    "        # for every value of the current_key\n",
    "        for i in range(len(full_dict[current_key])):\n",
    "            specific_dict = specific_dict.copy()\n",
    "            specific_dict[current_key] = full_dict[current_key][i]\n",
    "            result = np.append(result, combine_parameters(keys, full_dict, specific_dict))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 2/30\n",
      "Epoch 3/30\n",
      "Epoch 4/30\n",
      "Epoch 5/30\n",
      "Epoch 6/30\n",
      "Epoch 7/30\n",
      "Epoch 8/30\n",
      "Epoch 9/30\n",
      "Epoch 10/30\n",
      "Epoch 11/30\n",
      "Epoch 12/30\n",
      "Epoch 13/30\n",
      "Epoch 14/30\n",
      "Epoch 15/30\n",
      "Epoch 16/30\n",
      "Epoch 17/30\n",
      "Epoch 18/30\n",
      "Epoch 19/30\n",
      "Epoch 20/30\n",
      "Epoch 21/30\n",
      "Epoch 22/30\n",
      "Epoch 23/30\n",
      "Epoch 24/30\n",
      "Epoch 25/30\n",
      "Epoch 26/30\n",
      "Epoch 27/30\n",
      "Epoch 28/30\n",
      "Epoch 29/30\n",
      "Epoch 30/30\n",
      "Epoch 1/30\n",
      "Epoch 2/30\n",
      "Epoch 3/30\n",
      "Epoch 4/30\n",
      "Epoch 5/30\n",
      "Epoch 6/30\n",
      "Epoch 7/30\n",
      "Epoch 8/30\n",
      "Epoch 9/30\n",
      "Epoch 10/30\n",
      "Epoch 11/30\n",
      "Epoch 12/30\n",
      "Epoch 13/30\n",
      "Epoch 14/30\n",
      "Epoch 15/30\n",
      "Epoch 16/30\n",
      "Epoch 17/30\n",
      "Epoch 18/30\n",
      "Epoch 19/30\n",
      "Epoch 20/30\n",
      "Epoch 21/30\n",
      "Epoch 22/30\n",
      "Epoch 23/30\n",
      "Epoch 24/30\n",
      "Epoch 25/30\n",
      "Epoch 26/30\n",
      "Epoch 27/30\n",
      "Epoch 28/30\n",
      "Epoch 29/30\n",
      "Epoch 30/30\n",
      "Epoch 1/30\n",
      "Epoch 2/30\n",
      "Epoch 3/30\n",
      "Epoch 4/30\n",
      "Epoch 5/30\n",
      "Epoch 6/30\n",
      "Epoch 7/30\n",
      "Epoch 8/30\n",
      "Epoch 9/30\n",
      "Epoch 10/30\n",
      "Epoch 11/30\n",
      "Epoch 12/30\n",
      "Epoch 13/30\n",
      "Epoch 14/30\n",
      "Epoch 15/30\n",
      "Epoch 16/30\n",
      "Epoch 17/30\n",
      "Epoch 18/30\n",
      "Epoch 19/30\n",
      "Epoch 20/30\n",
      "Epoch 21/30\n",
      "Epoch 22/30\n",
      "Epoch 23/30\n",
      "Epoch 24/30\n",
      "Epoch 25/30\n",
      "Epoch 26/30\n",
      "Epoch 27/30\n",
      "Epoch 28/30\n",
      "Epoch 29/30\n",
      "Epoch 30/30\n",
      "Epoch 1/40\n",
      "Epoch 2/40\n",
      "Epoch 3/40\n",
      "Epoch 4/40\n",
      "Epoch 5/40\n",
      "Epoch 6/40\n",
      "Epoch 7/40\n",
      "Epoch 8/40\n",
      "Epoch 9/40\n",
      "Epoch 10/40\n",
      "Epoch 11/40\n",
      "Epoch 12/40\n",
      "Epoch 13/40\n",
      "Epoch 14/40\n",
      "Epoch 15/40\n",
      "Epoch 16/40\n",
      "Epoch 17/40\n",
      "Epoch 18/40\n",
      "Epoch 19/40\n",
      "Epoch 20/40\n",
      "Epoch 21/40\n",
      "Epoch 22/40\n",
      "Epoch 23/40\n",
      "Epoch 24/40\n",
      "Epoch 25/40\n",
      "Epoch 26/40\n",
      "Epoch 27/40\n",
      "Epoch 28/40\n",
      "Epoch 29/40\n",
      "Epoch 30/40\n",
      "Epoch 31/40\n",
      "Epoch 32/40\n",
      "Epoch 33/40\n",
      "Epoch 34/40\n",
      "Epoch 35/40\n",
      "Epoch 36/40\n",
      "Epoch 37/40\n",
      "Epoch 38/40\n",
      "Epoch 39/40\n",
      "Epoch 40/40\n",
      "Epoch 1/40\n",
      "Epoch 2/40\n",
      "Epoch 3/40\n",
      "Epoch 4/40\n",
      "Epoch 5/40\n",
      "Epoch 6/40\n",
      "Epoch 7/40\n",
      "Epoch 8/40\n",
      "Epoch 9/40\n",
      "Epoch 10/40\n",
      "Epoch 11/40\n",
      "Epoch 12/40\n",
      "Epoch 13/40\n",
      "Epoch 14/40\n",
      "Epoch 15/40\n",
      "Epoch 16/40\n",
      "Epoch 17/40\n",
      "Epoch 18/40\n",
      "Epoch 19/40\n",
      "Epoch 20/40\n",
      "Epoch 21/40\n",
      "Epoch 22/40\n",
      "Epoch 23/40\n",
      "Epoch 24/40\n",
      "Epoch 25/40\n",
      "Epoch 26/40\n",
      "Epoch 27/40\n",
      "Epoch 28/40\n",
      "Epoch 29/40\n",
      "Epoch 30/40\n",
      "Epoch 31/40\n",
      "Epoch 32/40\n",
      "Epoch 33/40\n",
      "Epoch 34/40\n",
      "Epoch 35/40\n",
      "Epoch 36/40\n",
      "Epoch 37/40\n",
      "Epoch 38/40\n",
      "Epoch 39/40\n",
      "Epoch 40/40\n",
      "Epoch 1/40\n",
      "Epoch 2/40\n",
      "Epoch 3/40\n",
      "Epoch 4/40\n",
      "Epoch 5/40\n",
      "Epoch 6/40\n",
      "Epoch 7/40\n",
      "Epoch 8/40\n",
      "Epoch 9/40\n",
      "Epoch 10/40\n",
      "Epoch 11/40\n",
      "Epoch 12/40\n",
      "Epoch 13/40\n",
      "Epoch 14/40\n",
      "Epoch 15/40\n",
      "Epoch 16/40\n",
      "Epoch 17/40\n",
      "Epoch 18/40\n",
      "Epoch 19/40\n",
      "Epoch 20/40\n",
      "Epoch 21/40\n",
      "Epoch 22/40\n",
      "Epoch 23/40\n",
      "Epoch 24/40\n",
      "Epoch 25/40\n",
      "Epoch 26/40\n",
      "Epoch 27/40\n",
      "Epoch 28/40\n",
      "Epoch 29/40\n",
      "Epoch 30/40\n",
      "Epoch 31/40\n",
      "Epoch 32/40\n",
      "Epoch 33/40\n",
      "Epoch 34/40\n",
      "Epoch 35/40\n",
      "Epoch 36/40\n",
      "Epoch 37/40\n",
      "Epoch 38/40\n",
      "Epoch 39/40\n",
      "Epoch 40/40\n",
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n",
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n",
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n",
      "Best: 0.064269 using {'epochs': 50, 'batch_size': 10}\n",
      "0.0667479928962 {'epochs': 30, 'batch_size': 10}\n",
      "0.0649827986907 {'epochs': 30, 'batch_size': 20}\n",
      "0.0669424202601 {'epochs': 30, 'batch_size': 30}\n",
      "0.0643803349683 {'epochs': 40, 'batch_size': 10}\n",
      "0.0645477365944 {'epochs': 40, 'batch_size': 20}\n",
      "0.0648495472352 {'epochs': 40, 'batch_size': 30}\n",
      "0.0642693405378 {'epochs': 50, 'batch_size': 10}\n",
      "0.0663648820895 {'epochs': 50, 'batch_size': 20}\n",
      "0.0652010681208 {'epochs': 50, 'batch_size': 30}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creates a model but does not compile the model\n",
    "def create_model(dropout_rate = 0.3):\n",
    "    layers            = 4\n",
    "    neurons           = 128\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(dropout_rate, input_shape=(stations, look_back)))\n",
    "    lstm = LSTM(256, recurrent_dropout=dropout_rate, return_sequences=True)\n",
    "    model.add(lstm)\n",
    "    for i in range(layers):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(neurons))\n",
    "    model.add(Dense(look_forward))\n",
    "    model.compile(loss=top_heavy_loss, optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0), metrics=[top_heavy_loss])\n",
    "    return model\n",
    "\n",
    "# The Parameters to Search Through\n",
    "dropout_rate = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "# Defines it as a dictionary\n",
    "param_grid = dict(dropout_rate=dropout_rate)\n",
    "\n",
    "# Begins the Search For the Optimal Properties\n",
    "grid_result = custom_grid_search(trainX, trainY, create_model, epochs=40, batch_size=10, param_grid=param_grid)\n",
    "\n",
    "# clears \n",
    "K.clear_session()\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result['best_results'], str(grid_result['best_parameters'])))\n",
    "\n",
    "loss = grid_result['results']\n",
    "params = grid_result['parameters']\n",
    "\n",
    "for l, p in zip(loss, params):\n",
    "    print l, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0686208955824 {'epochs': 5, 'batch_size': 20}\n",
      "0.0745190880896 {'epochs': 5, 'batch_size': 40}\n",
      "0.0822066692752 {'epochs': 5, 'batch_size': 60}\n",
      "0.0817830799339 {'epochs': 5, 'batch_size': 80}\n",
      "0.066416942638 {'epochs': 10, 'batch_size': 20}\n",
      "0.0739703796702 {'epochs': 10, 'batch_size': 40}\n",
      "0.0696016757825 {'epochs': 10, 'batch_size': 60}\n",
      "0.0752343996508 {'epochs': 10, 'batch_size': 80}\n",
      "0.0682121706503 {'epochs': 20, 'batch_size': 20}\n",
      "0.0690306955101 {'epochs': 20, 'batch_size': 40}\n",
      "0.0732031173911 {'epochs': 20, 'batch_size': 60}\n",
      "0.0684854398054 {'epochs': 20, 'batch_size': 80}\n",
      "0.0652724351692 {'epochs': 30, 'batch_size': 20}\n",
      "0.067623995967 {'epochs': 30, 'batch_size': 40}\n",
      "0.0665243551986 {'epochs': 30, 'batch_size': 60}\n",
      "0.0748547133832 {'epochs': 30, 'batch_size': 80}\n",
      "0.0652830774526 {'epochs': 40, 'batch_size': 20}\n",
      "0.0654454992653 {'epochs': 40, 'batch_size': 40}\n",
      "0.0658704056574 {'epochs': 40, 'batch_size': 60}\n",
      "0.0800149064402 {'epochs': 40, 'batch_size': 80}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = grid_result['results']\n",
    "params = grid_result['parameters']\n",
    "\n",
    "for l, p in zip(loss, params):\n",
    "    print l, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Best: 0.064020 using {'epochs': 40, 'batch_size': 20}\n",
    "0.0669075761485 {'epochs': 10, 'batch_size': 20}\n",
    "0.0718928324607 {'epochs': 10, 'batch_size': 40}\n",
    "0.0704617485391 {'epochs': 10, 'batch_size': 60}\n",
    "0.0653233264552 {'epochs': 20, 'batch_size': 20}\n",
    "0.06774414633   {'epochs': 20, 'batch_size': 40}\n",
    "0.0692400951415 {'epochs': 20, 'batch_size': 60}\n",
    "0.0648723018114 {'epochs': 30, 'batch_size': 20}\n",
    "0.0720279630803 {'epochs': 30, 'batch_size': 40}\n",
    "0.0669507312808 {'epochs': 30, 'batch_size': 60}\n",
    "0.0640200174334 {'epochs': 40, 'batch_size': 20}\n",
    "0.0727290603898 {'epochs': 40, 'batch_size': 40}\n",
    "0.0679111944213 {'epochs': 40, 'batch_size': 60}\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
